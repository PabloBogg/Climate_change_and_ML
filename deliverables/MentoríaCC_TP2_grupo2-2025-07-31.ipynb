{"cells":[{"cell_type":"markdown","id":"72cd4483","metadata":{"id":"72cd4483"},"source":["# MENTORÍA 06\n","# **Cambio climático y ML: cómo mitigar las emisiones de CO2 mediante la reducción del consumo energético en construcciones edilicias**\n","\n","**TP N°2: Análisis exploratorio y curación**\n","\n","Fecha de entrega: **29 de julio**"]},{"cell_type":"markdown","id":"b491c70d","metadata":{"id":"b491c70d"},"source":["## Consignas generales\n","\n","En este segundo TP deberemos asegurarnos de que nuestro dataset esté listo para introducirlo a un modelo.\n","Al igual que en el TP anterior, les propongo la elaboración de un informe donde se aclare o se detalle las decisiones tomadas.\n","Podemos tener más de un set de datos (o escenarios), de forma tal de poder analizar combinaciones diferentes de features que creamos puedan tener incidencia en nuestras predicciones. Les propongo contar con al menos dos escenarios (pueden evaluar más de dos, por supuesto):\n","\n","    - Escenario base: datos sin escalar y con todas las features.\n","    - Escenario 2: datos escalados y con las mejoras que hayan realizado.\n","    \n","De esta manera, podremos comparar qué tan buenas fueron nuestras elecciones, al contrastar las métricas que obtendremos con el peor de los modelos que podríamos haber usado."]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"If1NTXoB0CEQ"},"id":"If1NTXoB0CEQ"},{"cell_type":"markdown","id":"c8c5753d","metadata":{"id":"c8c5753d"},"source":["## Pasos a seguir para evitar el train-test data leaking\n","\n","1- Renombrar columnas o transformar unidades de medición.\n","\n","2- Chequear datos repetidos.\n","\n","3- Chequear \"missingness\" o valores faltantes:\n","\n","Verificar que las columnas numéricas correspondan a un tipo de dato numérico. Muchas veces, los valores faltantes se llenan con algún string como \"NA\", '.', o \"-\". En ese caso, un dato numérico (float o int) tendrá el tipo object.\n","    \n","        1- df.info() --> chequeo tipo de datos\n","        2- df.coldeinteres.unique() --> si veo una columna misteriosa, analizo los valores que contiene\n","        3- df.describe --> Si con un describe (o un value_counts) identifican valores == 0 en features que no deberían tener 0, entonces, ahí hay otro dato falante incorporado como 0.\n","\n","Si encuentran algo así, deben reemplazar esos valores con \"missing value\" o NaN:\n","\n","        1- df = pd.read_csv('data.csv', na_values='-')\n","        2- df.replace('-', np.nan)\n","        2- df.coldeinteres[df.coldeinteres == 0] = np.nan\n","\n","Si deciden eliminar alguna columna por presentar muchos valores faltantes, pueden hacerlo en esta etapa.\n","\n","Pero, si deciden imputar, deberán hacerlo más adelante.\n","    \n","----------------------------------------------------------------------------------------------------------------------------------\n","\n","Los puntos anteriores los pueden realizar con la totalidad del dataset. Sin embargo, previo a trabajar con las variables numéricas o cuantitativas que requieran escalado, chequeo de outliers, o evaluación de valores faltantes para imputar, debemos **DIVIDIR EL DATA SET EN TRAIN Y TEST**. De lo contrario, estaríamos comentiendo lo que se conoce como **contaminación train-test (un tipo de data leaking).**\n","\n","-----------------------------------------------------------------------------------------------------------------------------------\n","\n","4- Separar la variable target y dividir el set de datos en train y test.\n","\n","        X = df.drop(['target'],axis=1)\n","        y = df['target']\n","\n","        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)        \n","        \n","5- Luego de identificar las variables categóricas o cualitativas, evaluar su distribución, reasignarlas (o no), encodearlas por separado. Pueden usar getdummies, OneHotEncoding o OrdinalEncoding, dependiendo el objetivo.\n","Durante el proceso, recordar dropear una de las categorías para evitar la multicolinealidad.\n","    \n","        X_train = pd.get_dummies(X_train, columns=[\"catcol1\", \"catcol2\"], drop_first=True)\n","        X_test = pd.get_dummies(X_test, columns=[\"catcol1\", \"catcol2\"], drop_first=True)\n","        \n","6- Escalar variables numéricas con el método .fit_transform en el set de entrenamiento, pero sólo con el método .transform en el set de testeo. Esto se hace para utilizar la media y el desvío calculados (si usamos StandardScaler, por ejemplo) únicamente con los datos de entrenamiento. Recuerden que los datos de test son datos que simulan provenir de la realidad, posterior al entrenamiento del modelo, y su función radica en testear que tan bien generaliza mi modelo con datos nuevos (ya que para eso estamos haciendo y entrenando nuestros modelos: para que predigan lo mejor posible sobre nuevos valores de features que nunca vio). Ejemplos:\n","\n","        scaler = StandardScaler()\n","        scaler.fit_transform(X_train)\n","        scaler.transform(X_test)\n","        \n","        scaler = MinMaxScaler()\n","        num_cols = [\"numcol1\",\"numcol2\",\"numcol3\"]\n","        X_train[num_cols] = scaler.fit_transform(X_train[num_cols])\n","        X_test[num_cols] = scaler.transform(X_test[num_cols])\n","\n","7- El proceso de imputar es similar al de escalado:\n","\n","        # Imputación\n","        my_imputer = SimpleImputer()\n","        imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))\n","        imputed_X_test = pd.DataFrame(my_imputer.transform(X_test))\n","\n","        # Como la imputación elimina los nombres de las columnas, hay que agregarlos de nuevo\n","        imputed_X_train.columns = X_train.columns\n","        imputed_X_test.columns = X_test.columns\n","        \n","-------------------------------------------------------------------------------------------------------------------------------------\n","\n","En cuanto al análisis de los outliers, va a depender si los necesitamos para corregir valores atípicos (temperaturas de 1000°C, por ejemplo) o si vamos a depender del análisis de la distribución de los datos y, por ende, de la mediana. En el primer caso, podemos usar todo el dataset. Pero en el segundo, deberíamos trabajar el set de train y le de test por separado.\n"]},{"cell_type":"markdown","id":"02fc7b94","metadata":{"id":"02fc7b94"},"source":["Fuentes:\n","\n","https://jahazielponce.com/kaggle-30-dias-ml-dias-12-14/\n","\n","https://towardsdatascience.com/the-dreaded-antagonist-data-leakage-in-machine-learning-5f08679852cc"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"Qs9zm3iL5oVo"},"id":"Qs9zm3iL5oVo"},{"cell_type":"markdown","source":["# **ESCENARIOS**"],"metadata":{"id":"8_rf_EHSvGFY"},"id":"8_rf_EHSvGFY"},{"cell_type":"markdown","source":["## ESCENEARIO BASE\n","\n","\n","\n"],"metadata":{"id":"fy2vRajUzHeo"},"id":"fy2vRajUzHeo"},{"cell_type":"markdown","source":["DESCRIPCION:\n","* Datos sin escalar.\n","* Todas las features.\n","* Imputacion de valores faltantes mediante _'SimpleImputer'_\n","* Encoding de variables categoricas mediante _'get_dummies'_\n"],"metadata":{"id":"TmquBYBUzfze"},"id":"TmquBYBUzfze"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"2LIFshuS0Dbe"},"id":"2LIFshuS0Dbe"},{"cell_type":"markdown","source":["## ESCENEARIO 1\n","\n","\n","\n"],"metadata":{"id":"SowY44P8k8P_"},"id":"SowY44P8k8P_"},{"cell_type":"markdown","source":["DESCRIPCION:\n","* Datos escalados con _'StandardScaler'_.\n","* Todas las features.\n","* Imputacion de valores faltantes mediante _'SimpleImputer'_\n","* Encoding de variables categoricas mediante _'get_dummies'_\n"],"metadata":{"id":"kssM8TG7lBU5"},"id":"kssM8TG7lBU5"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"k93NbBGMvh0K"},"id":"k93NbBGMvh0K"},{"cell_type":"markdown","source":["## ESCENEARIO 2"],"metadata":{"id":"eAQMf2tbz4HZ"},"id":"eAQMf2tbz4HZ"},{"cell_type":"markdown","source":["**Escenerio conservador** donde se tienen en cuenta no solo todas las variables\n","que se consideran relevantes sino tambien algunas adicionales, no se eliminan registros, se imputan datos faltantes.\n","\n","DESCRIPCION:\n","\n","* Datos escalados.\n","* Imputcion de valores faltantes:\n","  * Se hace la imputacion en las variables 'año_construccion' (por su bajo porcentaje de valor faltantes, **2,4%**) y 'calificacion_energystar' (por su importancia para predecir la variable target, **-0,51 de correlacion**).\n","* Variables categoricas:\n","  * Eliminacion de 'clase_edificio', la informacion esta contemplada en 'tipo_instalacion'.\n","  * Codificadas con metodo _'get_dummies'_\n","* Variables de temperatura por mes:\n","  * Eliminacion de todas las 'nombreMes_temp_promedio', se conservan solo los minimos y maximos de cada mes, con esta informacion ya se esta contemplando el promedio.\n","* Variables meteorologicas:\n","  * Eliminacion de las 3 variables asociadas al viento ('direccion_velocidad_viento_maxima', 'direccion_velocidad_viento_pico' y 'velocidad_viento_maxima') y la de niebla ('dias_con_niebla'), por el gran procentaje de valores faltantes, **>50%**.\n","  *\n","\n","* Dudas:\n","  * En la variable 'año_construccion' hay 6 datos con el valor 0 (cero): ¿como afecta esto al modelo?.\n","\n","      \n","     \n","              \n","\n","\n"],"metadata":{"id":"NASLt81Az4HZ"},"id":"NASLt81Az4HZ"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"boUpGDSI0EvO"},"id":"boUpGDSI0EvO"},{"cell_type":"markdown","source":["## ESCENEARIO 3"],"metadata":{"id":"FSQ-cw_Iz53U"},"id":"FSQ-cw_Iz53U"},{"cell_type":"markdown","source":["**Escenerio arriesgado** donde solo se tienen en cuenta las variables que se consideran relevantes, se eliminan registros que se consideran que pueden afectar al modelo, no se imputan datos faltantes para no agregar informacion estimada al data set.\n","\n","DESCRIPCION:\n","\n","* Datos escalados.\n","* Valores faltantes:\n","  * En aquellas variables que contengan datos faltantes, se elimina directamente el registro, para no introducir error en el set de datos.\n","* Variables categoricas:\n","  * Eliminacion de 'clase_edificio', la informacion esta contemplada en 'tipo_instalacion'.\n","* Variables de temperatura:\n","  * Solo se considera 'temperatura_promedio'.\n","* Variables meteorologicas:\n","  * Eliminacion de las 3 variables asociadas al viento ('direccion_velocidad_viento_maxima', 'direccion_velocidad_viento_pico' y 'velocidad_viento_maxima') y la de niebla ('dias_con_niebla'), por el gran procentaje de valores faltantes, **>50%**.\n","  \n","\n","\n"],"metadata":{"id":"0ihaHnjtz53V"},"id":"0ihaHnjtz53V"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"e-2__qE70FvF"},"id":"e-2__qE70FvF"},{"cell_type":"markdown","source":["## ESCENEARIO 4\n","\n","DESCRIPCION:\n","\n","+ Eliminación de las variables climaticas\n"," + Variables relacionadas a viento y niebla\n"," + Variables de rango de temperatura, quitando minimo y maximo para solo conservar promedio por mes\n","+ Se descarta la variable \"tipo de instalación\" preeviendo que su informacion este correctamtente representada en la variables \"clase de edificio\"\n","+ La implementacion de un pipeline que impute los datos faltantes con \"_IterativeImputer_\" con un máximo de 100 iteraciones y luego escale los datos con \"_StandardScaler_\".\n","\n","\n"],"metadata":{"id":"xwKYOL5DioOy"},"id":"xwKYOL5DioOy"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"tBgdYnjpi5an"},"id":"tBgdYnjpi5an"},{"cell_type":"markdown","source":["## ESCENEARIO 5\n","\n","DESCRIPCION:\n","\n","+ Eliminación de las variables climaticas\n"," + Variables relacionadas a viento y niebla\n"," + Variables de temperatura promedio, valor minimo y valor maximo\n","+ Creación de una nueva variable climatica donde se promedian los meses agrupados por estacion.  \n","+ Nuevamente se descarta la variable \"tipo de instalación\" preeviendo que su informacion este correctamtente representada en la variables \"clase de edificio\"\n","+ La implementacion de un pipeline que impute los datos faltantes con \"SimpleImputer\" utilizando la **mediana** y luego escale los datos con \"_StandardScaler_\".\n","\n"],"metadata":{"id":"_x3VKiopi1yH"},"id":"_x3VKiopi1yH"},{"cell_type":"markdown","source":["---"],"metadata":{"id":"QIa3guFmi6dH"},"id":"QIa3guFmi6dH"},{"cell_type":"markdown","source":["# CURACION DE DATOS"],"metadata":{"id":"s3J6nj-kbQmE"},"id":"s3J6nj-kbQmE"},{"cell_type":"markdown","source":["### 1) PASOS EN COMUN PARA TODOS LOS ESCENARIOS"],"metadata":{"id":"OH_0jBT0bhDk"},"id":"OH_0jBT0bhDk"},{"cell_type":"code","source":["# Instalacion\n","!pip install pandas numpy seaborn matplotlib missingno"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-6Vl-a_b7RW","outputId":"b680ed7a-086d-4106-86be-49cc7d332f14"},"id":"F-6Vl-a_b7RW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: missingno in /usr/local/lib/python3.11/dist-packages (0.5.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from missingno) (1.16.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}]},{"cell_type":"code","source":["# Importacion\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import missingno as msno\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.experimental import enable_iterative_imputer\n","from sklearn.impute import SimpleImputer, IterativeImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.compose import ColumnTransformer"],"metadata":{"id":"fVvZqaSBb72t"},"id":"fVvZqaSBb72t","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Importacion del data set\n","df = pd.read_csv(\"data.csv\")"],"metadata":{"id":"JoW00gygb_sD"},"id":"JoW00gygb_sD","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.1) Renombrar columnas y transformar unidades de medición"],"metadata":{"id":"kg_9gOD0boaS"},"id":"kg_9gOD0boaS"},{"cell_type":"code","source":["# Renombrar columnas\n","df=df.rename(columns={\n","    'Year_Factor': 'factor_año',\n","    'State_Factor': 'factor_estado',\n","    'building_class': 'clase_edificio',\n","    'facility_type': 'tipo_instalacion',\n","    'floor_area': 'area_edificio',\n","    'year_built': 'año_construccion',\n","    'energy_star_rating': 'calificacion_energystar',\n","    'ELEVATION': 'elevacion',\n","    'january_min_temp': 'enero_temp_min',\n","    'january_avg_temp': 'enero_temp_promedio',\n","    'january_max_temp': 'enero_temp_max',\n","    'february_min_temp': 'febrero_temp_min',\n","    'february_avg_temp': 'febrero_temp_promedio',\n","    'february_max_temp': 'febrero_temp_max',\n","    'march_min_temp': 'marzo_temp_min',\n","    'march_avg_temp': 'marzo_temp_promedio',\n","    'march_max_temp': 'marzo_temp_max',\n","    'april_min_temp': 'abril_temp_min',\n","    'april_avg_temp': 'abril_temp_promedio',\n","    'april_max_temp': 'abril_temp_max',\n","    'may_min_temp': 'mayo_temp_min',\n","    'may_avg_temp': 'mayo_temp_promedio',\n","    'may_max_temp': 'mayo_temp_max',\n","    'june_min_temp': 'junio_temp_min',\n","    'june_avg_temp': 'junio_temp_promedio',\n","    'june_max_temp': 'junio_temp_max',\n","    'july_min_temp': 'julio_temp_min',\n","    'july_avg_temp': 'julio_temp_promedio',\n","    'july_max_temp': 'julio_temp_max',\n","    'august_min_temp': 'agosto_temp_min',\n","    'august_avg_temp': 'agosto_temp_promedio',\n","    'august_max_temp': 'agosto_temp_max',\n","    'september_min_temp': 'septiembre_temp_min',\n","    'september_avg_temp': 'septiembre_temp_promedio',\n","    'september_max_temp': 'septiembre_temp_max',\n","    'october_min_temp': 'octubre_temp_min',\n","    'october_avg_temp': 'octubre_temp_promedio',\n","    'october_max_temp': 'octubre_temp_max',\n","    'november_min_temp': 'noviembre_temp_min',\n","    'november_avg_temp': 'noviembre_temp_promedio',\n","    'november_max_temp': 'noviembre_temp_max',\n","    'december_min_temp': 'diciembre_temp_min',\n","    'december_avg_temp': 'diciembre_temp_promedio',\n","    'december_max_temp': 'diciembre_temp_max',\n","    'cooling_degree_days': 'grados_dia_enfriamiento',\n","    'heating_degree_days': 'grados_dia_calefaccion',\n","    'precipitation_inches': 'precipitacion_mm',\n","    'snowfall_inches': 'nevada_mm',\n","    'snowdepth_inches': 'profundidad_nieve_mm',\n","    'avg_temperature': 'temperatura_promedio',\n","    'days_below_30F':'dias_menos_1C',\n","    'days_below_20F': 'dias_menos_6C',\n","    'days_below_10F': 'dias_menos_12C',\n","    'days_below_0F': 'dias_menos_18C',\n","    'days_above_80F': 'dias_mas_27C',\n","    'days_above_90F': 'dias_mas_32C',\n","    'days_above_100F': 'dias_mas_38C',\n","    'days_above_110F': 'dias_mas_43C',\n","    'direction_max_wind_speed': 'direccion_velocidad_viento_maxima',\n","    'direction_peak_wind_speed': 'direccion_velocidad_viento_pico',\n","    'max_wind_speed': 'velocidad_viento_maxima',\n","    'days_with_fog': 'dias_con_niebla',\n","    'site_eui': 'consumo',\n","})"],"metadata":{"id":"9vN58t6WcRlE"},"id":"9vN58t6WcRlE","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cambio de unidades\n","\n","  # consumo -> kBtu/ft² to kWh/m²\n","df['consumo']= df['consumo'] * 3.1546\n","df['consumo'] = df['consumo'].round(2)\n","\n","  # temperatura -> °F to °C\n","temp_cols = [col for col in df.columns if 'temp' in col]\n","df_temp = df[temp_cols]\n","df_temp_C=(df_temp-32)* (5/9)\n","df_temp_C = df_temp_C.round(2)\n","df[temp_cols] = df_temp_C\n","\n","  # precipitaciones -> inches to mm\n","precip_cols = [col for col in df.columns if 'inches' in col]\n","df_precip = df[precip_cols]\n","df_precip_mm = df_precip * 25.4\n","df_precip_mm = df_precip_mm.round(2)\n","df[precip_cols] = df_precip_mm\n","\n","  # areas -> ft² to m²\n","df['area_edificio']= df['area_edificio'] * 0.092903\n","df['area_edificio'] = df['area_edificio'].round(2)\n","\n","  # velocidad -> mph to km/h\n","df['velocidad_viento_maxima']= df['velocidad_viento_maxima'] * 1.60934\n","df['velocidad_viento_maxima'] = df['velocidad_viento_maxima'].round(2)"],"metadata":{"id":"tW9gCJP2cY0n"},"id":"tW9gCJP2cY0n","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1.2) Chequear datos repetidos"],"metadata":{"id":"yvKRrOxudT8W"},"id":"yvKRrOxudT8W"},{"cell_type":"code","source":["print(\"Filas duplicadas:\")\n","print(df.duplicated().sum())\n","\n","print(\"\\nFilas duplicadas (mostrando las duplicadas):\")\n","print(df[df.duplicated(keep=False)].sort_values(by=list(df.columns)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ppGd0R0d-9f","outputId":"e62f2272-add5-4409-bc07-99384e88d07b"},"id":"8ppGd0R0d-9f","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Filas duplicadas:\n","0\n","\n","Filas duplicadas (mostrando las duplicadas):\n","Empty DataFrame\n","Columns: [factor_año, factor_estado, clase_edificio, tipo_instalacion, area_edificio, año_construccion, calificacion_energystar, elevacion, enero_temp_min, enero_temp_promedio, enero_temp_max, febrero_temp_min, febrero_temp_promedio, febrero_temp_max, marzo_temp_min, marzo_temp_promedio, marzo_temp_max, abril_temp_min, abril_temp_promedio, abril_temp_max, mayo_temp_min, mayo_temp_promedio, mayo_temp_max, junio_temp_min, junio_temp_promedio, junio_temp_max, julio_temp_min, julio_temp_promedio, julio_temp_max, agosto_temp_min, agosto_temp_promedio, agosto_temp_max, septiembre_temp_min, septiembre_temp_promedio, septiembre_temp_max, octubre_temp_min, octubre_temp_promedio, octubre_temp_max, noviembre_temp_min, noviembre_temp_promedio, noviembre_temp_max, diciembre_temp_min, diciembre_temp_promedio, diciembre_temp_max, grados_dia_enfriamiento, grados_dia_calefaccion, precipitacion_mm, nevada_mm, profundidad_nieve_mm, avg_temp, dias_menos_1C, dias_menos_6C, dias_menos_12C, dias_menos_18C, dias_mas_27C, dias_mas_32C, dias_mas_38C, dias_mas_43C, direccion_velocidad_viento_maxima, direccion_velocidad_viento_pico, velocidad_viento_maxima, dias_con_niebla, consumo, id]\n","Index: []\n","\n","[0 rows x 64 columns]\n"]}]},{"cell_type":"markdown","source":["#### 1.3) Chequear \"missingness\" o valores faltantes\n","\n","\n"],"metadata":{"id":"YkUGVr36dia2"},"id":"YkUGVr36dia2"},{"cell_type":"code","source":["# Identificar columnas con tipo 'object'\n","object_cols = df.select_dtypes(include='object').columns\n","\n","# Verificar si hay valores como \"NA\", \".\", o \"-\" en columnas 'object'\n","missing_markers = [\"NA\", \"\\.\", \"-\"]\n","for col in object_cols:\n","  for marker in missing_markers:\n","    if df[col].astype(str).str.contains(marker).any():\n","      print(f\"La columna '{col}' de tipo 'object' contiene el valor '{marker}'\")"],"metadata":{"id":"d4pSWMT0etWg"},"id":"d4pSWMT0etWg","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["No se observan caracteres especiales en las variables categoricas"],"metadata":{"id":"t7e3OQFBhDUq"},"id":"t7e3OQFBhDUq"},{"cell_type":"markdown","source":["### 2) PASOS PARA ESCENARIO BASE"],"metadata":{"id":"T1ph2nrvitYa"},"id":"T1ph2nrvitYa"},{"cell_type":"markdown","source":["#### 2.1) Separar la variable target y dividir el set de datos en train y test."],"metadata":{"id":"z_7h1HZYi9U6"},"id":"z_7h1HZYi9U6"},{"cell_type":"code","source":["# Copia del data set para el escenario base\n","df_escBase = df.copy()\n","\n","# Separacion de la variable target\n","X_escBase = df_escBase.drop('consumo', axis=1)\n","y_escBase = df_escBase['consumo']\n","\n","# Dividir el set de datos de entrenamiento y testeo (70-30)\n","X_train_escBase, X_test_escBase, y_train_escBase, y_test_escBase = train_test_split(X_escBase, y_escBase, test_size=0.3, random_state=42)\n","\n","print(\"Separacion en set de train y test completo usando train_tes_split.\")\n","print(f\"X_train_escBase shape: {X_train_escBase.shape}\")\n","print(f\"X_test_escBase shape: {X_test_escBase.shape}\")\n","print(f\"y_train_escBase shape: {y_train_escBase.shape}\")\n","print(f\"y_test_escBase shape: {y_test_escBase.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hB72vZVkj1VV","outputId":"312a2694-54a2-4d88-8775-818d35565dd8"},"id":"hB72vZVkj1VV","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Separacion en set de train y test completo usando train_tes_split.\n","X_train_escBase shape: (53029, 63)\n","X_test_escBase shape: (22728, 63)\n","y_train_escBase shape: (53029,)\n","y_test_escBase shape: (22728,)\n"]}]},{"cell_type":"markdown","source":["#### 2.2) Encoding"],"metadata":{"id":"gN5Fa2HNjItW"},"id":"gN5Fa2HNjItW"},{"cell_type":"markdown","source":[" Luego de identificar las variables categóricas o cualitativas, evaluar su distribución, reasignarlas (o no), encodearlas por separado. Pueden usar getdummies, OneHotEncoding o OrdinalEncoding, dependiendo el objetivo. Durante el proceso, recordar dropear una de las categorías para evitar la multicolinealidad."],"metadata":{"id":"Z7I5AjuolTYL"},"id":"Z7I5AjuolTYL"},{"cell_type":"code","source":["# Identificar las columnas categoricas y numericas para X_train y X_test\n","categorical_cols = X_train_escBase.select_dtypes(include=['object', 'category']).columns\n","numerical_cols = X_train_escBase.select_dtypes(include=np.number).columns\n","\n","# Encoding mediante get_dummies\n","X_train_escBase_encoded = pd.get_dummies(X_train_escBase, columns=categorical_cols, drop_first=True, dtype=int)\n","X_test_escBase_encoded = pd.get_dummies(X_test_escBase, columns=categorical_cols, drop_first=True, dtype=int)\n","\n","print(\"Encoding completo usando get_dummies.\")\n","print(f\"X_train_escBase_encoded shape: {X_train_escBase_encoded.shape}\")\n","print(f\"X_test_escBase_encoded shape: {X_test_escBase_encoded.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6LGY4_soA00","outputId":"39ebe360-0070-4cd2-baa2-b30b05ae7cd0"},"id":"l6LGY4_soA00","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding completo usando get_dummies.\n","X_train_escBase_encoded shape: (53029, 126)\n","X_test_escBase_encoded shape: (22728, 126)\n"]}]},{"cell_type":"markdown","source":["#### 2.3) Imputacion"],"metadata":{"id":"bPg_vVHxl563"},"id":"bPg_vVHxl563"},{"cell_type":"code","source":["print(\"Valores faltantes en X_train (ANTES de la imputacion)\")\n","print(X_train_escBase_encoded.isnull().sum().sort_values(ascending=False).head(10))\n","\n","print(\"\\nValores faltantes en X_test (ANTES de la imputacion)\")\n","print(X_test_escBase_encoded.isnull().sum().sort_values(ascending=False).head(10))\n","\n","\n","# Inicializacion de SimpleImputer (mean)\n","imputer_escBase = SimpleImputer(strategy='mean')\n","\n","# Columnas numericas despues del encoding, se elimina 'id'\n","numerical_cols_after_encoding = X_train_escBase_encoded.select_dtypes(include=np.number).columns.tolist()\n","if 'id' in numerical_cols_after_encoding:\n","    numerical_cols_after_encoding.remove('id')\n","\n","\n","# Imputar X_train\n","X_train_escBase_encoded[numerical_cols_after_encoding] = imputer_escBase.fit_transform(X_train_escBase_encoded[numerical_cols_after_encoding])\n","\n","# Imputar X_test\n","X_test_escBase_encoded[numerical_cols_after_encoding] = imputer_escBase.transform(X_test_escBase_encoded[numerical_cols_after_encoding])\n","\n","\n","print(\"\\nValores faltantes en X_train (DESPUES de la imputacion)\")\n","print(X_train_escBase_encoded.isnull().sum().sort_values(ascending=False).head(10))\n","\n","print(\"\\nValores faltantes en X_test (DESPUES de la imputacion)\")\n","print(X_test_escBase_encoded.isnull().sum().sort_values(ascending=False).head(10))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9vnJzPJ62G0O","outputId":"5918dba6-b62c-4636-9e4f-f18496fe7c5c"},"id":"9vnJzPJ62G0O","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Valores faltantes en X_train (ANTES de la imputacion)\n","dias_con_niebla                      32023\n","direccion_velocidad_viento_pico      29380\n","direccion_velocidad_viento_maxima    28847\n","velocidad_viento_maxima              28847\n","calificacion_energystar              18832\n","año_construccion                      1280\n","enero_temp_promedio                      0\n","enero_temp_max                           0\n","febrero_temp_min                         0\n","febrero_temp_promedio                    0\n","dtype: int64\n","\n","Valores faltantes en X_test (ANTES de la imputacion)\n","dias_con_niebla                      13773\n","direccion_velocidad_viento_pico      12431\n","direccion_velocidad_viento_maxima    12235\n","velocidad_viento_maxima              12235\n","calificacion_energystar               7877\n","año_construccion                       557\n","enero_temp_promedio                      0\n","enero_temp_max                           0\n","febrero_temp_min                         0\n","febrero_temp_promedio                    0\n","dtype: int64\n","\n","Valores faltantes en X_train (DESPUES de la imputacion)\n","factor_año                 0\n","area_edificio              0\n","año_construccion           0\n","calificacion_energystar    0\n","elevacion                  0\n","enero_temp_min             0\n","enero_temp_promedio        0\n","enero_temp_max             0\n","febrero_temp_min           0\n","febrero_temp_promedio      0\n","dtype: int64\n","\n","Valores faltantes en X_test (DESPUES de la imputacion)\n","factor_año                 0\n","area_edificio              0\n","año_construccion           0\n","calificacion_energystar    0\n","elevacion                  0\n","enero_temp_min             0\n","enero_temp_promedio        0\n","enero_temp_max             0\n","febrero_temp_min           0\n","febrero_temp_promedio      0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["# Set de datos finales para Escenario Base\n","X_train_final_escBase = X_train_escBase_encoded\n","X_test_final_escBase = X_test_escBase_encoded\n","y_train_final_escBase = y_train_escBase\n","y_test_final_escBase = y_test_escBase"],"metadata":{"id":"qVevDIB440Io"},"id":"qVevDIB440Io","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 3) PASOS PARA ESCENARIO 1"],"metadata":{"id":"Hn3-EO-Z263H"},"id":"Hn3-EO-Z263H"},{"cell_type":"markdown","source":["Este escenario es similar al base solo que con escalado e imputacion."],"metadata":{"id":"1uDAm_qN3I3B"},"id":"1uDAm_qN3I3B"},{"cell_type":"markdown","metadata":{"id":"f5e5e3a5"},"source":["#### 3.1) Separar la variable target y dividir el set de datos en train y test."],"id":"f5e5e3a5"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03e23964","outputId":"56404da4-7fb7-491f-c0cd-180c53edfd1e"},"source":["\n","# Copia del data set para el escenario 1 (ex Base 2)\n","df_escBase2 = df.copy()\n","\n","# Separacion de la variable target\n","X_escBase2 = df_escBase2.drop('consumo', axis=1)\n","y_escBase2 = df_escBase2['consumo']\n","\n","# Dividir el set de datos de entrenamiento y testeo (70-30)\n","X_train_escBase2, X_test_escBase2, y_train_escBase2, y_test_escBase2 = train_test_split(X_escBase2, y_escBase2, test_size=0.3, random_state=42)\n","\n","print(\"Separacion en set de train y test completo usando train_tes_split para escBase2.\")\n","print(f\"X_train_escBase2 shape: {X_train_escBase2.shape}\")\n","print(f\"X_test_escBase2 shape: {X_test_escBase2.shape}\")\n","print(f\"y_train_escBase2 shape: {y_train_escBase2.shape}\")\n","print(f\"y_test_escBase2 shape: {y_test_escBase2.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Separacion en set de train y test completo usando train_tes_split para escBase2.\n","X_train_escBase2 shape: (53029, 63)\n","X_test_escBase2 shape: (22728, 63)\n","y_train_escBase2 shape: (53029,)\n","y_test_escBase2 shape: (22728,)\n"]}],"id":"03e23964"},{"cell_type":"markdown","metadata":{"id":"c3d554cf"},"source":["#### 3.2) Encoding"],"id":"c3d554cf"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0272676a","outputId":"72db4f3f-760d-4f3b-a48e-1112e94de8dd"},"source":["# Identificar las columnas categoricas y numericas para X_train y X_test de escBase2\n","categorical_cols_escBase2 = X_train_escBase2.select_dtypes(include=['object', 'category']).columns\n","numerical_cols_escBase2 = X_train_escBase2.select_dtypes(include=np.number).columns\n","\n","# Encoding mediante get_dummies\n","X_train_escBase2_encoded = pd.get_dummies(X_train_escBase2, columns=categorical_cols_escBase2, drop_first=True, dtype=int)\n","X_test_escBase2_encoded = pd.get_dummies(X_test_escBase2, columns=categorical_cols_escBase2, drop_first=True, dtype=int)\n","\n","print(\"Encoding completo usando get_dummies para escBase2.\")\n","print(f\"X_train_escBase2_encoded shape: {X_train_escBase2_encoded.shape}\")\n","print(f\"X_test_escBase2_encoded shape: {X_test_escBase2_encoded.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding completo usando get_dummies para escBase2.\n","X_train_escBase2_encoded shape: (53029, 126)\n","X_test_escBase2_encoded shape: (22728, 126)\n"]}],"id":"0272676a"},{"cell_type":"markdown","metadata":{"id":"6729b876"},"source":["#### 3.3) Imputacion"],"id":"6729b876"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"304b77b0","outputId":"b9c4e972-26d2-49c4-a3c5-d26ec842232e"},"source":["print(\"Valores faltantes en X_train_escBase2 (ANTES de la imputacion)\")\n","print(X_train_escBase2_encoded.isnull().sum().sort_values(ascending=False).head(10))\n","\n","print(\"\\nValores faltantes en X_test_escBase2 (ANTES de la imputacion)\")\n","print(X_test_escBase2_encoded.isnull().sum().sort_values(ascending=False).head(10))\n","\n","\n","# Inicializacion de SimpleImputer (mean) para escBase2\n","imputer_escBase2 = SimpleImputer(strategy='mean')\n","\n","# Columnas numericas despues del encoding para escBase2, se elimina 'id'\n","numerical_cols_after_encoding_escBase2 = X_train_escBase2_encoded.select_dtypes(include=np.number).columns.tolist()\n","if 'id' in numerical_cols_after_encoding_escBase2:\n","    numerical_cols_after_encoding_escBase2.remove('id')\n","\n","\n","# Imputar X_train_escBase2\n","X_train_escBase2_encoded[numerical_cols_after_encoding_escBase2] = imputer_escBase2.fit_transform(X_train_escBase2_encoded[numerical_cols_after_encoding_escBase2])\n","\n","# Imputar X_test_escBase2\n","X_test_escBase2_encoded[numerical_cols_after_encoding_escBase2] = imputer_escBase2.transform(X_test_escBase2_encoded[numerical_cols_after_encoding_escBase2])\n","\n","\n","print(\"\\nValores faltantes en X_train_escBase2 (DESPUES de la imputacion)\")\n","print(X_train_escBase2_encoded.isnull().sum().sort_values(ascending=False).head(10))\n","\n","print(\"\\nValores faltantes en X_test_escBase2 (DESPUES de la imputacion)\")\n","print(X_test_escBase2_encoded.isnull().sum().sort_values(ascending=False).head(10))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Valores faltantes en X_train_escBase2 (ANTES de la imputacion)\n","dias_con_niebla                      32023\n","direccion_velocidad_viento_pico      29380\n","direccion_velocidad_viento_maxima    28847\n","velocidad_viento_maxima              28847\n","calificacion_energystar              18832\n","año_construccion                      1280\n","enero_temp_promedio                      0\n","enero_temp_max                           0\n","febrero_temp_min                         0\n","febrero_temp_promedio                    0\n","dtype: int64\n","\n","Valores faltantes en X_test_escBase2 (ANTES de la imputacion)\n","dias_con_niebla                      13773\n","direccion_velocidad_viento_pico      12431\n","direccion_velocidad_viento_maxima    12235\n","velocidad_viento_maxima              12235\n","calificacion_energystar               7877\n","año_construccion                       557\n","enero_temp_promedio                      0\n","enero_temp_max                           0\n","febrero_temp_min                         0\n","febrero_temp_promedio                    0\n","dtype: int64\n","\n","Valores faltantes en X_train_escBase2 (DESPUES de la imputacion)\n","factor_año                 0\n","area_edificio              0\n","año_construccion           0\n","calificacion_energystar    0\n","elevacion                  0\n","enero_temp_min             0\n","enero_temp_promedio        0\n","enero_temp_max             0\n","febrero_temp_min           0\n","febrero_temp_promedio      0\n","dtype: int64\n","\n","Valores faltantes en X_test_escBase2 (DESPUES de la imputacion)\n","factor_año                 0\n","area_edificio              0\n","año_construccion           0\n","calificacion_energystar    0\n","elevacion                  0\n","enero_temp_min             0\n","enero_temp_promedio        0\n","enero_temp_max             0\n","febrero_temp_min           0\n","febrero_temp_promedio      0\n","dtype: int64\n"]}],"id":"304b77b0"},{"cell_type":"markdown","metadata":{"id":"b639ec6b"},"source":["#### 3.4) Escalado"],"id":"b639ec6b"},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f70bde47","outputId":"46a1feb9-ce45-4db5-e646-e6e83af26f85"},"source":["# Identificar columnas numéricas después del encoding e imputación para escBase2\n","numerical_cols_final_escBase2 = X_train_escBase2_encoded.select_dtypes(include=np.number).columns.tolist()\n","if 'id' in numerical_cols_final_escBase2:\n","    numerical_cols_final_escBase2.remove('id') # Eliminar la columna 'id' si existe\n","\n","# Inicializar StandardScaler para escBase2\n","scaler_escBase2 = StandardScaler()\n","\n","# Escalar las columnas numéricas en el conjunto de entrenamiento de escBase2\n","X_train_escBase2_scaled = scaler_escBase2.fit_transform(X_train_escBase2_encoded[numerical_cols_final_escBase2])\n","\n","# Escalar las columnas numéricas en el conjunto de prueba de escBase2 (usando el scaler ajustado en el entrenamiento)\n","X_test_escBase2_scaled = scaler_escBase2.transform(X_test_escBase2_encoded[numerical_cols_final_escBase2])\n","\n","# Convertir los arrays escalados de vuelta a DataFrames, manteniendo los nombres de las columnas\n","X_train_escBase2_encoded[numerical_cols_final_escBase2] = X_train_escBase2_scaled\n","X_test_escBase2_encoded[numerical_cols_final_escBase2] = X_test_escBase2_scaled\n","\n","\n","print(\"Escalado completo usando StandardScaler para escBase2.\")\n","print(f\"X_train_escBase2_encoded shape después del escalado: {X_train_escBase2_encoded.shape}\")\n","print(f\"X_test_escBase2_encoded shape después del escalado: {X_test_escBase2_encoded.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Escalado completo usando StandardScaler para escBase2.\n","X_train_escBase2_encoded shape después del escalado: (53029, 126)\n","X_test_escBase2_encoded shape después del escalado: (22728, 126)\n"]}],"id":"f70bde47"},{"cell_type":"code","metadata":{"id":"1384fc4b"},"source":["# Set de datos finales para Escenario Base 2\n","X_train_final_escBase2 = X_train_escBase2_encoded\n","X_test_final_escBase2 = X_test_escBase2_encoded\n","y_train_final_escBase2 = y_train_escBase2\n","y_test_final_escBase2 = y_test_escBase2"],"execution_count":null,"outputs":[],"id":"1384fc4b"},{"cell_type":"markdown","source":["### 4) PASOS PARA ESCENARIO 2"],"metadata":{"id":"BF7M4wWQ5TT5"},"id":"BF7M4wWQ5TT5"},{"cell_type":"markdown","source":["#### 4.1) Planteo de variables a eliminar y creacion de df_esc2"],"metadata":{"id":"dTs6vvWZ1Ryt"},"id":"dTs6vvWZ1Ryt"},{"cell_type":"code","source":["# Lista de columnas específicas a eliminar\n","columnas_especificas_a_eliminar = [ 'clase_edificio',\n","                                    'direccion_velocidad_viento_maxima',\n","                                    'direccion_velocidad_viento_pico' ,\n","                                    'velocidad_viento_maxima' ,\n","                                    'dias_con_niebla']\n","# Identificar las columnas que contienen '_temp_promedio' en su nombre\n","columnas_promedio_a_eliminar = [col for col in df.columns if '_temp_promedio' in col]\n","# Combinar ambas listas de columnas a eliminar\n","todas_las_columnas_a_eliminar = columnas_especificas_a_eliminar + columnas_promedio_a_eliminar\n","# Eliminar todas las columnas especificadas en la lista combinada\n","df_esc2 = df.drop(todas_las_columnas_a_eliminar, axis=1)"],"metadata":{"id":"JjLRT6A9vDOK"},"execution_count":null,"outputs":[],"id":"JjLRT6A9vDOK"},{"cell_type":"markdown","source":["#### 4.2) Separar la variable target, dividir set e imputación."],"metadata":{"id":"8tj6T0CM1ht_"},"id":"8tj6T0CM1ht_"},{"cell_type":"code","source":["# Separar la variable target\n","X_esc2 = df_esc2.drop('consumo', axis=1)\n","y_esc2 = df_esc2['consumo']\n","\n","# Dividir el set de datos en train y test\n","# Uso random_state para que la división sea la misma que en el escenario base\n","X_train_esc2, X_test_esc2, y_train_esc2, y_test_esc2 = train_test_split(X_esc2, y_esc2, test_size=0.3, random_state=42)\n","\n","print(f\"Dimensiones X_train_esc2 antes de imputar: {X_train_esc2.shape}\")\n","print(f\"Dimensiones X_test_esc2 antes de imputar: {X_test_esc2.shape}\")\n","\n","# Columnas específicas a imputar\n","columnas_a_imputar = ['año_construccion', 'calificacion_energystar']\n","\n","# Inicializar el imputador (uso la media, probar otra)\n","imputer_esc2 = SimpleImputer(strategy='mean')\n","\n","# Aplicar la imputación solo a las columnas especificadas en el conjunto de entrenamiento\n","X_train_esc2[columnas_a_imputar] = imputer_esc2.fit_transform(X_train_esc2[columnas_a_imputar])\n","\n","# Aplicar la imputación solo a las columnas especificadas en el conjunto de prueba\n","X_test_esc2[columnas_a_imputar] = imputer_esc2.transform(X_test_esc2[columnas_a_imputar])\n","\n","print(\"\\nValores faltantes en X_train_esc2 después de imputar:\")\n","print(X_train_esc2[columnas_a_imputar].isnull().sum())\n","\n","print(\"\\nValores faltantes en X_test_esc2 después de imputar:\")\n","print(X_test_esc2[columnas_a_imputar].isnull().sum())\n"],"metadata":{"id":"BCCUe1Mqzcbz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f094421-c03f-49c5-a75a-59aa1e7e33c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dimensiones X_train_esc2 antes de imputar: (53029, 46)\n","Dimensiones X_test_esc2 antes de imputar: (22728, 46)\n","\n","Valores faltantes en X_train_esc2 después de imputar:\n","año_construccion           0\n","calificacion_energystar    0\n","dtype: int64\n","\n","Valores faltantes en X_test_esc2 después de imputar:\n","año_construccion           0\n","calificacion_energystar    0\n","dtype: int64\n"]}],"id":"BCCUe1Mqzcbz"},{"cell_type":"markdown","source":["#### 4.3) Escalado."],"metadata":{"id":"iP_VdIFW12DR"},"id":"iP_VdIFW12DR"},{"cell_type":"code","source":["# Escalar variables numéricas imputadas\n","# Identificar las columnas numéricas imputadas para escalar (excluir 'id')\n","# Asegurarnos de que estamos trabajando con los dataframes después de la imputación\n","numerical_cols_to_scale_esc2 = X_train_esc2.select_dtypes(include=np.number).columns.tolist()\n","if 'id' in numerical_cols_to_scale_esc2:\n","    numerical_cols_to_scale_esc2.remove('id')\n","\n","# Inicializar el escalador\n","scaler_esc2 = StandardScaler()\n","\n","# Aplicar fit_transform al set de entrenamiento (imputado)\n","X_train_escenario2_final = X_train_esc2.copy()\n","X_train_escenario2_final[numerical_cols_to_scale_esc2] = scaler_esc2.fit_transform(X_train_escenario2_final[numerical_cols_to_scale_esc2])\n","\n","# Aplicar solo transform al set de testeo (imputado)\n","X_test_escenario2_final = X_test_esc2.copy()\n","X_test_escenario2_final[numerical_cols_to_scale_esc2] = scaler_esc2.transform(X_test_escenario2_final[numerical_cols_to_scale_esc2])\n","\n","\n","print(\"\\nX_train_escenario2_final (primeras 5 filas con numéricas escaladas):\")\n","print(X_train_escenario2_final.head())\n","\n","print(\"\\nX_test_escenario2_final (primeras 5 filas con numéricas escaladas):\")\n","print(X_test_escenario2_final.head())\n","\n","# Verificar las estadísticas de las columnas escaladas en train y test\n","print(\"\\nEstadísticas de columnas numéricas escaladas en X_train_escenario2_final:\")\n","print(X_train_escenario2_final[numerical_cols_to_scale_esc2].describe().loc[['mean', 'std']])\n","\n","print(\"\\nEstadísticas de columnas numéricas escaladas en X_test_escenario2_final:\")\n","print(X_test_escenario2_final[numerical_cols_to_scale_esc2].describe().loc[['mean', 'std']])\n","\n","# Set de datos finales para Escenario 2\n","# X_train_escenario2_final, X_test_escenario2_final, y_train_esc2, y_test_esc2 ya están definidos arriba,\n","# estas son las variables a usar para el entrenamiento"],"metadata":{"id":"6tjH5Lcvzmsk","colab":{"base_uri":"https://localhost:8080/"},"outputId":"2223bc4d-e916-4891-e568-1586de5368da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","X_train_escenario2_final (primeras 5 filas con numéricas escaladas):\n","       factor_año factor_estado           tipo_instalacion  area_edificio  \\\n","13184    1.108561       State_4  Education_Other_classroom      -0.326554   \n","18163   -1.604780       State_6       Office_Uncategorized       1.691065   \n","74041    1.108561      State_11        5plus_Unit_Building      -0.394751   \n","16247   -2.283115       State_6       Office_Uncategorized      11.044662   \n","50301    0.430226       State_6  Multifamily_Uncategorized      -0.445340   \n","\n","       año_construccion  calificacion_energystar  elevacion  enero_temp_min  \\\n","13184          0.182698                -0.004180   2.659445       -1.432769   \n","18163          1.034244                 1.083317  -0.406136        0.164327   \n","74041          0.732082                -2.266174  -0.216737        1.763341   \n","16247          0.484859                 0.387319   0.054790       -0.579578   \n","50301         -0.668849                -0.308679  -0.231822       -0.366760   \n","\n","       enero_temp_max  febrero_temp_min  ...  avg_temp  dias_menos_1C  \\\n","13184       -1.690125         -0.773749  ... -1.166040       1.565442   \n","18163        0.551052          0.655523  ...  0.528125      -0.966427   \n","74041       -0.571217          1.767496  ... -0.459469      -1.545139   \n","16247       -1.128991          0.259614  ...  0.150752       0.190999   \n","50301       -0.571217         -0.773749  ...  0.295278       0.516525   \n","\n","       dias_menos_6C  dias_menos_12C  dias_menos_18C  dias_mas_27C  \\\n","13184       1.693158        1.989181        1.757838      1.197886   \n","18163      -0.858645       -0.689201       -0.303066     -0.421547   \n","74041      -1.203483       -0.689201       -0.303066     -2.277971   \n","16247      -0.444839       -0.548234       -0.303066      0.052433   \n","50301       1.141417        0.579506       -0.303066      0.921398   \n","\n","       dias_mas_32C  dias_mas_38C  dias_mas_43C     id  \n","13184      2.362713     -0.125533     -0.015699  13184  \n","18163      0.266885     -0.125533     -0.015699  18163  \n","74041     -1.008835     -0.125533     -0.015699  74041  \n","16247      0.175762      0.323618     -0.015699  16247  \n","50301     -0.188729     -0.125533     -0.015699  50301  \n","\n","[5 rows x 46 columns]\n","\n","X_test_escenario2_final (primeras 5 filas con numéricas escaladas):\n","       factor_año factor_estado                tipo_instalacion  \\\n","29922   -0.926445       State_6                   Lodging_Hotel   \n","55120    1.108561       State_6       Education_Other_classroom   \n","52830    1.108561       State_6       Multifamily_Uncategorized   \n","47809    0.430226       State_6            Office_Uncategorized   \n","4663     1.108561       State_1  Office_Bank_or_other_financial   \n","\n","       area_edificio  año_construccion  calificacion_energystar  elevacion  \\\n","29922       0.368346          1.034244            -3.090853e-16  -0.406136   \n","55120      -0.401859         -0.668849             1.561816e+00  -0.603916   \n","52830      -0.256191         -0.311749             1.698196e-01  -0.481561   \n","47809       0.273735          0.127759             7.353182e-01  -0.303894   \n","4663       -0.631000         -0.586441             1.083317e+00  -0.620677   \n","\n","       enero_temp_min  enero_temp_max  febrero_temp_min  ...  avg_temp  \\\n","29922       -0.048491        0.362887          0.418264  ... -0.322972   \n","55120       -0.048491       -0.010082         -1.011009  ...  0.463891   \n","52830       -0.048491       -0.010082         -1.011009  ...  0.463891   \n","47809       -0.366760       -0.571217         -0.773749  ...  0.295278   \n","4663         2.721982        0.551052          2.403522  ...  1.547835   \n","\n","       dias_menos_1C  dias_menos_6C  dias_menos_12C  dias_menos_18C  \\\n","29922       0.046321      -0.444839       -0.689201       -0.303066   \n","55120      -0.315375      -0.444839       -0.407266        0.040418   \n","52830      -0.315375      -0.444839       -0.407266        0.040418   \n","47809       0.516525       1.141417        0.579506       -0.303066   \n","4663       -1.762157      -1.203483       -0.689201       -0.303066   \n","\n","       dias_mas_27C  dias_mas_32C  dias_mas_38C  dias_mas_43C     id  \n","29922     -0.303052     -0.279852     -0.125533     -0.015699  29922  \n","55120      0.526414      0.266885     -0.125533     -0.015699  55120  \n","52830      0.526414      0.266885     -0.125533     -0.015699  52830  \n","47809      0.921398     -0.188729     -0.125533     -0.015699  47809  \n","4663      -2.633456     -1.099958     -0.125533     -0.015699   4663  \n","\n","[5 rows x 46 columns]\n","\n","Estadísticas de columnas numéricas escaladas en X_train_escenario2_final:\n","        factor_año  area_edificio  año_construccion  calificacion_energystar  \\\n","mean  1.953594e-16   1.236740e-16      1.364032e-15            -3.265369e-16   \n","std   1.000009e+00   1.000009e+00      1.000009e+00             1.000009e+00   \n","\n","         elevacion  enero_temp_min  enero_temp_max  febrero_temp_min  \\\n","mean -5.058174e-17    5.821924e-17   -3.225172e-16      3.012126e-16   \n","std   1.000009e+00    1.000009e+00    1.000009e+00      1.000009e+00   \n","\n","      febrero_temp_max  marzo_temp_min  ...  profundidad_nieve_mm  \\\n","mean     -3.526652e-16   -3.215792e-18  ...          4.676298e-17   \n","std       1.000009e+00    1.000009e+00  ...          1.000009e+00   \n","\n","          avg_temp  dias_menos_1C  dias_menos_6C  dias_menos_12C  \\\n","mean -1.243842e-15  -5.064873e-17   3.195694e-17   -5.909019e-17   \n","std   1.000009e+00   1.000009e+00   1.000009e+00    1.000009e+00   \n","\n","      dias_menos_18C  dias_mas_27C  dias_mas_32C  dias_mas_38C  dias_mas_43C  \n","mean    1.145626e-17  2.224256e-16  6.485181e-17  1.098729e-17  1.339914e-19  \n","std     1.000009e+00  1.000009e+00  1.000009e+00  1.000009e+00  1.000009e+00  \n","\n","[2 rows x 43 columns]\n","\n","Estadísticas de columnas numéricas escaladas en X_test_escenario2_final:\n","      factor_año  area_edificio  año_construccion  calificacion_energystar  \\\n","mean    0.004505       0.003790         -0.003774                -0.004458   \n","std     0.993748       1.066386          1.017944                 1.010854   \n","\n","      elevacion  enero_temp_min  enero_temp_max  febrero_temp_min  \\\n","mean   0.004204       -0.006790       -0.000337         -0.004847   \n","std    1.054515        0.997656        0.999935          0.995700   \n","\n","      febrero_temp_max  marzo_temp_min  ...  profundidad_nieve_mm  avg_temp  \\\n","mean          0.006203       -0.003804  ...              0.005595 -0.001699   \n","std           0.991365        0.995122  ...              0.996753  0.999766   \n","\n","      dias_menos_1C  dias_menos_6C  dias_menos_12C  dias_menos_18C  \\\n","mean       0.004481      -0.000466       -0.001197       -0.006371   \n","std        0.992687       0.993059        0.989334        0.980271   \n","\n","      dias_mas_27C  dias_mas_32C  dias_mas_38C  dias_mas_43C  \n","mean      0.004909     -0.003781      0.000075      0.008720  \n","std       0.995431      0.990795      1.038270      1.206099  \n","\n","[2 rows x 43 columns]\n"]}],"id":"6tjH5Lcvzmsk"},{"cell_type":"markdown","source":["### 5) PASOS PARA ESCENARIO 3"],"metadata":{"id":"DUjqnr7y7kd0"},"id":"DUjqnr7y7kd0"},{"cell_type":"markdown","source":["#### 5.1) Eliminacion de variables  "],"metadata":{"id":"7uCtzILFJ7Nv"},"id":"7uCtzILFJ7Nv"},{"cell_type":"markdown","source":["Se listan las variables del data set que no se tendran en cuenta para el escenario 3, justificando cada decision:\n","'Year_Factor': 'factor_año':\n","* 'clase_edificio': no aporta informacion adicional, esta contemplada en la variable 'facility_type': 'tipo_instalacion'.\n","* 'mes_temp_min', 'mes_temp_promedio' y 'mes_temp_max': se resume todo en la variable 'temperatura_promedio'.\n","*  'direccion_velocidad_viento_maxima', 'direccion_velocidad_viento_pico', 'velocidad_viento_maxima', 'dias_con_niebla': por el gran procentaje de valores faltantes.\n","\n","El data set queda con las siguientes variables:\n","\n","    'State_Factor': 'factor_estado',\n","    'facility_type': 'tipo_instalacion',\n","    'floor_area': 'area_edificio',\n","    'year_built': 'año_construccion',\n","    'energy_star_rating': 'calificacion_energystar',\n","    'ELEVATION': 'elevacion',\n","    'cooling_degree_days': 'grados_dia_enfriamiento',\n","    'heating_degree_days': 'grados_dia_calefaccion',\n","    'precipitation_inches': 'precipitacion_mm',\n","    'snowfall_inches': 'nevada_mm',\n","    'snowdepth_inches': 'profundidad_nieve_mm',\n","    'avg_temperature': 'temperatura_promedio',\n","    'days_below_30F':'dias_menos_1C',\n","    'days_below_20F': 'dias_menos_6C',\n","    'days_below_10F': 'dias_menos_12C',\n","    'days_below_0F': 'dias_menos_18C',\n","    'days_above_80F': 'dias_mas_27C',\n","    'days_above_90F': 'dias_mas_32C',\n","    'days_above_100F': 'dias_mas_38C',\n","    'days_above_110F': 'dias_mas_43C',\n","    'site_eui': 'consumo',\n","\n","   \n","\n","\n"],"metadata":{"id":"Qq7DZpsbKDI-"},"id":"Qq7DZpsbKDI-"},{"cell_type":"code","source":["# Copia del data set para el escenario 3\n","df_esc3 = df.copy()"],"metadata":{"id":"QONSjIlWN2vP"},"id":"QONSjIlWN2vP","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Columnas a conservar para el escenario 3\n","cols_to_keep_esc3 = [\n","    'factor_estado',\n","    'tipo_instalacion',\n","    'area_edificio',\n","    'año_construccion',\n","    'calificacion_energystar',\n","    'elevacion',\n","    'grados_dia_enfriamiento',\n","    'grados_dia_calefaccion',\n","    'precipitacion_mm',\n","    'nevada_mm',\n","    'profundidad_nieve_mm',\n","    'temperatura_promedio',\n","    'dias_menos_1C',\n","    'dias_menos_6C',\n","    'dias_menos_12C',\n","    'dias_menos_18C',\n","    'dias_mas_27C',\n","    'dias_mas_32C',\n","    'dias_mas_38C',\n","    'dias_mas_43C',\n","    'consumo',\n","    'id'\n","]\n","\n","# Eliminar columnas no deseadas del dataframe\n","cols_to_drop_esc3 = [col for col in df_esc3.columns if col not in cols_to_keep_esc3]\n","df_esc3 = df_esc3.drop(columns=cols_to_drop_esc3)\n","\n","print(\"Columnas restantes en df_esc3 para el escenario 3:\")\n","print(df_esc3.columns)\n","print(f\"df_esc3 shape: {df_esc3.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j47IyLa4N9Ce","outputId":"ee1d9692-4a77-4883-9897-7c2282270fe1"},"id":"j47IyLa4N9Ce","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Columnas restantes en df_esc3 para el escenario 3:\n","Index(['factor_estado', 'tipo_instalacion', 'area_edificio',\n","       'año_construccion', 'calificacion_energystar', 'elevacion',\n","       'grados_dia_enfriamiento', 'grados_dia_calefaccion', 'precipitacion_mm',\n","       'nevada_mm', 'profundidad_nieve_mm', 'dias_menos_1C', 'dias_menos_6C',\n","       'dias_menos_12C', 'dias_menos_18C', 'dias_mas_27C', 'dias_mas_32C',\n","       'dias_mas_38C', 'dias_mas_43C', 'consumo', 'id'],\n","      dtype='object')\n","df_esc3 shape: (75757, 21)\n"]}]},{"cell_type":"markdown","source":["#### 5.2) Eliminacion de registros"],"metadata":{"id":"vRuiT7TGOTPr"},"id":"vRuiT7TGOTPr"},{"cell_type":"markdown","source":["Se eliminan los registros con algun dato faltante para no imputar e introducir datos estimados en el data set."],"metadata":{"id":"aNMNNV1zOYKO"},"id":"aNMNNV1zOYKO"},{"cell_type":"code","source":["# Calculo de valores faltantes antes de eliminarlos\n","missing_before = df_esc3.isnull().sum()\n","print(\"Valores faltantes por columna ANTES de eliminar registros:\")\n","print(missing_before[missing_before > 0])\n","\n","print(\"\\nTamaño del set de datos ANTES de eliminar registros:\")\n","print(f\"df_esc3 shape: {df_esc3.shape}\")\n","\n","# Numero de registros antes de eliminar\n","rows_before = df_esc3.shape[0]\n","\n","# Eliminacion de registros con datos faltantes\n","df_esc3 = df_esc3.dropna()\n","\n","# Numero de registros despues de eliminar\n","rows_after = df_esc3.shape[0]\n","\n","# Calculo del numero de registros eliminados\n","rows_removed = rows_before - rows_after\n","print(f\"\\nNúmero total de registros eliminados: {rows_removed}\")\n","\n","# Tamaño del data set despues de eliminar registros\n","print(\"\\nTamaño del set de datos DESPUES de eliminar registros:\")\n","print(f\"df_esc3 shape: {df_esc3.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eDkkY52wOwBs","outputId":"bd07f8b5-d0d8-40ee-b31f-c7b89ecec0d4"},"id":"eDkkY52wOwBs","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Valores faltantes por columna ANTES de eliminar registros:\n","año_construccion            1837\n","calificacion_energystar    26709\n","dtype: int64\n","\n","Tamaño del set de datos ANTES de eliminar registros:\n","df_esc3 shape: (75757, 21)\n","\n","Número total de registros eliminados: 27312\n","\n","Tamaño del set de datos DESPUES de eliminar registros:\n","df_esc3 shape: (48445, 21)\n"]}]},{"cell_type":"markdown","source":["#### 5.3) Separar la variable target y dividir el set de datos en train y test."],"metadata":{"id":"thvHTRRnJIrp"},"id":"thvHTRRnJIrp"},{"cell_type":"code","source":["# Separacion de la variable target\n","X_esc3 = df_esc3.drop('consumo', axis=1)\n","y_esc3 = df_esc3['consumo']\n","\n","# Dividir el set de datos de entrenamiento y testeo (70-30)\n","X_train_esc3, X_test_esc3, y_train_esc3, y_test_esc3 = train_test_split(X_esc3, y_esc3, test_size=0.3, random_state=10)\n","\n","print(\"Separacion en set de train y test completo usando train_tes_split.\")\n","print(f\"X_train_esc3 shape: {X_train_esc3.shape}\")\n","print(f\"X_test_esc3 shape: {X_test_esc3.shape}\")\n","print(f\"y_train_esc3 shape: {y_train_esc3.shape}\")\n","print(f\"y_test_esc3 shape: {y_test_esc3.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFamEWcNJI7_","outputId":"91e67fde-598c-48f5-a3a2-b301039c6717"},"id":"LFamEWcNJI7_","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Separacion en set de train y test completo usando train_tes_split.\n","X_train_esc3 shape: (33911, 20)\n","X_test_esc3 shape: (14534, 20)\n","y_train_esc3 shape: (33911,)\n","y_test_esc3 shape: (14534,)\n"]}]},{"cell_type":"markdown","source":["#### 5.4) Encoding"],"metadata":{"id":"GEKSS8oqV03L"},"id":"GEKSS8oqV03L"},{"cell_type":"code","source":["# Identificar las columnas categoricas y numericas para X_train y X_test\n","categorical_cols = X_train_esc3.select_dtypes(include=['object', 'category']).columns\n","numerical_cols = X_train_esc3.select_dtypes(include=np.number).columns\n","\n","# Encoding mediante get_dummies\n","X_train_esc3_encoded = pd.get_dummies(X_train_esc3, columns=categorical_cols, drop_first=True, dtype=int)\n","X_test_esc3_encoded = pd.get_dummies(X_test_esc3, columns=categorical_cols, drop_first=True, dtype=int)\n","\n","print(\"Encoding completo usando get_dummies.\")\n","print(f\"X_train_esc3_encoded shape: {X_train_esc3_encoded.shape}\")\n","print(f\"X_test_esc3_encoded shape: {X_test_esc3_encoded.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HPE4ervNV4cC","outputId":"ea2a9e32-e454-4abe-f641-89795fd1524c"},"id":"HPE4ervNV4cC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding completo usando get_dummies.\n","X_train_esc3_encoded shape: (33911, 62)\n","X_test_esc3_encoded shape: (14534, 62)\n"]}]},{"cell_type":"code","source":["# Set de datos finales para Escenario 3\n","X_train_final_esc3 = X_train_esc3_encoded\n","X_test_final_esc3 = X_test_esc3_encoded\n","y_train_final_esc3 = y_train_esc3\n","y_test_final_esc3 = y_test_esc3"],"metadata":{"id":"TaALivv842SG"},"id":"TaALivv842SG","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 6) PASOS PARA ESCENARIO 4\n"],"metadata":{"id":"ROn8LyyNjRee"},"id":"ROn8LyyNjRee"},{"cell_type":"code","source":["# Step 0: Copy df1 to df_esc1\n","df_esc1 = df.copy()\n","\n","# Step 1: Drop unwanted columns\n","temp_cols_to_drop = [col for col in df_esc1.columns if ('_temp_min' in col or '_temp_max' in col)]\n","wind_fog_cols_to_drop = [col for col in df_esc1.columns if ('viento' in col or 'niebla' in col)]\n","\n","df_esc1 = df_esc1.drop(columns=temp_cols_to_drop + wind_fog_cols_to_drop + ['tipo_instalacion'])\n","\n","# Step 2: Separate target\n","X = df_esc1.drop(columns=['consumo'])\n","y = df_esc1['consumo']\n","\n","# Step 3: Train/test split before anything else\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Step 4: Separate column types\n","numerical_cols = X.select_dtypes(include='number').columns.tolist()\n","categorical_cols = X.select_dtypes(include='object').columns.tolist()\n","\n","# Step 5: Numerical pipeline (impute + scale)\n","numerical_pipeline = Pipeline(steps=[\n","    ('imputer', IterativeImputer(max_iter=100, random_state=0)),\n","    ('scaler', StandardScaler())\n","])\n","\n","# Fit and transform numeric features\n","X_train_num = pd.DataFrame(\n","    numerical_pipeline.fit_transform(X_train[numerical_cols]),\n","    columns=numerical_cols,\n","    index=X_train.index\n",")\n","X_test_num = pd.DataFrame(\n","    numerical_pipeline.transform(X_test[numerical_cols]),\n","    columns=numerical_cols,\n","    index=X_test.index\n",")\n","\n","# Step 6: Categorical preprocessing using get_dummies\n","X_train_cat = pd.get_dummies(X_train[categorical_cols], drop_first=True, dtype=int)\n","X_test_cat = pd.get_dummies(X_test[categorical_cols], drop_first=True, dtype=int)\n","\n","# Align test dummies to match train columns\n","X_test_cat = X_test_cat.reindex(columns=X_train_cat.columns, fill_value=0)\n","\n","# Step 7: Concatenate final datasets\n","X_train_final = pd.concat([X_train_num, X_train_cat], axis=1)\n","X_test_final = pd.concat([X_test_num, X_test_cat], axis=1)\n","\n","# Step 8: Renaming of variables\n","\n","X_train_esc_4=X_train_final\n","X_test_esc_4=X_test_final\n","y_train_esc_4=y_train\n","y_test_esc_4=y_test\n","\n","# Optional: check the shape\n","print(\"X Train shape:\", X_train_esc_4.shape)\n","print(\"X Test shape:\", X_test_esc_4.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zY0QRe5zjbFH","outputId":"761dd1af-2e54-45f5-810f-a8f2f42ef339"},"id":"zY0QRe5zjbFH","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X Train shape: (60605, 39)\n","X Test shape: (15152, 39)\n"]}]},{"cell_type":"markdown","source":["### 7) PASOS PARA ESCENARIO 5"],"metadata":{"id":"DPA24VprjkJh"},"id":"DPA24VprjkJh"},{"cell_type":"code","source":["# Step 0: Copy base\n","df_esc2 = df.copy()\n","\n","# Step 1: Drop unwanted columns\n","drop_cols = [col for col in df_esc2.columns if (\n","    '_temp_min' in col or '_temp_max' in col or 'viento' in col or 'niebla' in col\n",")]\n","df_esc2 = df_esc2.drop(columns=drop_cols)\n","\n","# Step 2: Create seasonal average columns\n","seasons = {\n","    'verano_temp_promedio': ['junio_temp_promedio', 'julio_temp_promedio', 'agosto_temp_promedio'],\n","    'otoño_temp_promedio': ['septiembre_temp_promedio', 'octubre_temp_promedio', 'noviembre_temp_promedio'],\n","    'invierno_temp_promedio': ['diciembre_temp_promedio', 'enero_temp_promedio', 'febrero_temp_promedio'],\n","    'primavera_temp_promedio': ['marzo_temp_promedio', 'abril_temp_promedio', 'mayo_temp_promedio']\n","}\n","\n","for season, months in seasons.items():\n","    df_esc2[season] = df_esc2[months].mean(axis=1)\n","\n","# Drop monthly columns\n","monthly_cols = [month for months in seasons.values() for month in months]\n","df_esc2 = df_esc2.drop(columns=monthly_cols)\n","\n","# Step 3: Split features and target\n","X = df_esc2.drop(columns=['consumo'])\n","y = df_esc2['consumo']\n","\n","# Step 4: Train-test split (before any transformation)\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# Step 5: Identify column types\n","numerical_cols = X.select_dtypes(include='number').columns.tolist()\n","categorical_cols = X.select_dtypes(include='object').columns.tolist()\n","\n","# Step 6: Numerical pipeline\n","numerical_pipeline = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler())\n","])\n","\n","# Fit numerical pipeline\n","X_train_num = pd.DataFrame(\n","    numerical_pipeline.fit_transform(X_train[numerical_cols]),\n","    columns=numerical_cols,\n","    index=X_train.index\n",")\n","X_test_num = pd.DataFrame(\n","    numerical_pipeline.transform(X_test[numerical_cols]),\n","    columns=numerical_cols,\n","    index=X_test.index\n",")\n","\n","# Step 7: Categorical preprocessing with get_dummies\n","X_train_cat = pd.get_dummies(X_train[categorical_cols], drop_first=True, dtype=int)\n","X_test_cat = pd.get_dummies(X_test[categorical_cols], drop_first=True, dtype=int)\n","\n","# Align test set\n","X_test_cat = X_test_cat.reindex(columns=X_train_cat.columns, fill_value=0)\n","\n","# Step 8: Concatenate final datasets\n","X_train_final = pd.concat([X_train_num, X_train_cat], axis=1)\n","X_test_final = pd.concat([X_test_num, X_test_cat], axis=1)\n","\n","# Step : Renaming of variables\n","\n","X_train_esc_5=X_train_final\n","X_test_esc_5=X_test_final\n","y_train_esc_5=y_train\n","y_test_esc_5=y_test\n","\n","# Optional: check the shape\n","print(\"X Train shape:\", X_train_esc_5.shape)\n","print(\"X Test shape:\", X_test_esc_5.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7YHyXLPNjj1V","outputId":"872c2134-0d5d-437c-943f-e21681947155"},"id":"7YHyXLPNjj1V","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["X Train shape: (60605, 90)\n","X Test shape: (15152, 90)\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[{"file_id":"1h9JOrKax3Y1M_CXQRPLX3gyHBFzpvH3b","timestamp":1754004489733}],"toc_visible":true}},"nbformat":4,"nbformat_minor":5}